
<!DOCTYPE HTML>
<html>
<head>
	<script data-cfasync="false" type="text/javascript" src="//use.typekit.net/axj3cfp.js"></script>
	<script data-cfasync="false" type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<meta charset="utf-8">
	<title>computer architecture final exam review  | KING</title>

<meta name="author" content="pb"> 

<meta name="description" content="king, KING, King, c/c++, robot, android, octopress, java, python, ruby, web, sae, cloud, ios, http, tcp, ip"> <meta name="keywords" content="king, KING, King, c/c++, robot, android, octopress, java, python, ruby, web, sae, cloud, ios, http, tcp, ip">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="KING" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script type="text/javascript" src="/javascripts/jquery.fancybox.pack.js"></script>

<script language="Javascript" type="text/javascript">
$(document).ready(
  function() {
    (function($) {
      $(".fancybox[data-content-id]").each(function() {
        this.href = $(this).data('content-id');
      });
      $(".fancybox").fancybox({
        beforeLoad: function() {
          var el, 
              id = $(this.element).data('title-id');

          if (id) {
            el = $('#' + id);

            if (el.length) {
              this.title = el.html();
            }
          }
          if ($(this).data('content')) {
            this.content = $(this).data('content');
          }
        },
        helpers: {
          title: {
            type: 'inside'
          }
        }
      });
    })(jQuery);
  }
);
</script>

	
</head>



<body>
	<header id="header" class="inner"><h1><a href="/">KING</a></h1>
<h4>Do more, say less</h4>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/about">About</a></li>
	<li><a href="/archives">Archive</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/about">About</a></li>
	<li><a href="/archives">Archive</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://www.google.com.hk/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:pbking1.github.com">
			</form>
		</div>
	</div>
</nav>


</header>

	<div id="content" class="inner"><article class="post">
	<h2 class="title">Computer Architecture Final Exam Review</h2>
	<div class="entry-content"><!--more-->


<h3>memory</h3>

<ul>
<li><p>Memory Hierarchy</p>

<ul>
<li>Understand what is memory wall? Why it is a bottleneck?瓶颈

<ul>
<li>内存壁垒：处理器和内存的悬殊持续增长</li>
<li>瓶颈：好的内存架构设计对系统的性能有越来越高的重要性</li>
</ul>
</li>
<li>Illusion provided from a memory hierarchy

<ul>
<li>大的内存都是很慢的，但是caching可以give 错觉他们很快</li>
<li>所以这个错觉可以是

<ul>
<li>caching + virtual memory 能够是的内存变快</li>
</ul>
</li>
<li>传统的内存层级

<ul>
<li>通过使用局部性的优势

<ul>
<li>能够尽可能的利用磁盘上能够使用的内存</li>
<li>速度也会很快</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Principle of locality (two types of locality)

<ul>
<li>定义:程序每次会使用一小部分的地址空间

<ul>
<li>temporal locality

<ul>
<li>曾经使用过的程序，再次被使用的可能会很大</li>
<li>比如循环中的指令和数据</li>
</ul>
</li>
<li>spatial locality

<ul>
<li>在执行过的程序附近的程序被使用的可能性很大</li>
<li>例如顺序执行中的数组</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>DDR RAM? Relationship between memory clock rate and memory bandwidth

<ul>
<li>mobile system require 2X bandwidth every 2 years</li>
</ul>
</li>
<li><p>DDR DRAM 叫double data rate DRAM</p>

<ul>
<li>transfer data on rising and falling clock edges</li>
<li>E.g., 800MHz DDR &ndash;> BW?</li>
</ul>
</li>
<li><p>Know how to calculate Average Disk Read Time</p>

<ul>
<li>average disk read time = seek time + rotation latency + transfer time + controller delay</li>
<li>rpm = revolution per minutes</li>
<li>e.g

<ul>
<li>512B sector, 15000rpm, 4ms average seek time, 100MB/s transfer rate, 0.2ms controller overhead, idle disk</li>
<li> time = 4ms seek time +

<ul>
<li>(&frac12;)/(15000/60) = 2ms rotationl latency</li>
<li>512/100MB/s = 5.12 s = 0.00512ms transfer time</li>
<li>0.2ms controller delay</li>
<li>= 6.2 ms</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Difference between three types of caches:</p>

<ul>
<li><strong>Direct-mapped cache</strong>

<ul>
<li>根据索引表映射哪个cache块用来存数据</li>
<li>一个block只能有一个选择存哪里</li>
<li>内存块的那一个位置分配给cache的某个位置，由后三位决定（假设有8个块（2<sup>3</sup>=8））

<ul>
<li>001：00001，01001，10001，11001</li>
</ul>
</li>
<li>用valid bit来判断cache的数据<strong>是否存在</strong>内存那个位置</li>
<li>tag用来判断cache的数据在内存哪个位置</li>
<li><strong>重点</strong>

<ul>
<li>index不存在cache里面，就像数组不会存索引</li>
<li>假设有一个word：22

<ul>
<li>首先转成二进制10110</li>
<li>然后后三位位index</li>
<li>前两位为tag</li>
<li>然后把数据存入对应位置</li>
<li>因为没存进来的时候，对应位置没有数据，所以为miss（第一次访问那个内存地址），存入之后，才会变成hit</li>
<li>然后数据valid bit变成Y</li>
</ul>
</li>
</ul>
</li>
<li> 假设一个cache有32 bit的地址

<ul>
<li> tag:22bits</li>
<li> index:4bits</li>
<li> offsets:6bits</li>
<li> 那么 cache block size 为2<sup>6</sup> byte</li>
<li> 那么 cache有2<sup>4</sup> entries</li>
</ul>
</li>
</ul>
</li>
<li>n-way Set-associative cache

<ul>
<li>每个set都有n个成员</li>
<li>用块的号数来决定哪个set</li>
<li>在给定的set中搜索全部成员（因为set里面的成员少，所以搜索起来快）

<ul>
<li>那么就只要比较n次，更加省时间</li>
</ul>
</li>
<li>假设一个cache有2<sup>s</sup>个sets， 并且每个block有2<sup>n</sup>个bytes。

<ul>
<li>那么block offset为n</li>
<li>index为s</li>
<li>假设address长度为m

<ul>
<li>则tag长度为m-s-n</li>
</ul>
</li>
<li>计算set index

<ul>
<li>block address = memory address / 2<sup>n</sup></li>
<li>set index = block address % 2<sup>s</sup></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Fully associative cache

<ul>
<li>cache可以映射到内存中任何一个位置</li>
<li>所有成员都要搜索一次</li>
<li>耗费时间长，每个成员都要对比, 每个block的tag都要对比</li>
</ul>
</li>
</ul>
</li>
<li>For each of the above cache type

<ul>
<li><p>How to calculate a block(or set) index give an address?</p>

<ul>
<li>miss: load 的数据不再memory里面

<ul>
<li>every miss always load the 64 byte</li>
</ul>
</li>
<li>如何选block size

<ul>
<li>用两种方式

<ul>
<li>early restart

<ul>
<li>CPU在等第一个byte，但是64byte还没load进去</li>
<li>或者可以先读第一个byte， 不用等他读完</li>
</ul>
</li>
<li>critical word first</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>How to subdivide an address given a cache design, or vice versa?</p></li>
</ul>
</li>
<li>Write back vs write through（write hit）

<ul>
<li>write through

<ul>
<li>如果write hit， 则更新缓存里面的block和memory里面的block</li>
<li>这样缓存和内存里面的数据就同步了</li>
<li>但是会使得数据的写更长时间

<ul>
<li>解决方案：使用write buffer

<ul>
<li>把要写入内存的数据hold waiting</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>write back</p>

<ul>
<li>当你更新数据的时候，只改cache里面的数据</li>
<li>速度快</li>
</ul>
</li>
<li><p>两者使用的差别</p>

<ul>
<li>如果写的频率高的时候，write back快</li>
</ul>
</li>
</ul>
</li>
<li>Write allocate vs no write allocate (on write miss)

<ul>
<li>allocate

<ul>
<li>fetch the block</li>
</ul>
</li>
<li>no allocate

<ul>
<li>do not fetch the block</li>
</ul>
</li>
</ul>
</li>
<li><p>condition</p>

<ul>
<li>if read hit: cpu continue</li>
<li>if write hit: write through or write back</li>
<li>if read miss: store pipeline, read data to pipeline and continue</li>
<li>if write miss: write through (allocate or no allocate)</li>
</ul>
</li>
<li><p>Know how to calculate AMAT, actual CPI</p>

<ul>
<li>AMAT: average memory access time

<ul>
<li>hit time + miss rate * miss penalty</li>
<li>如果是两层

<ul>
<li>AMAT = hit time1 + miss rate1 * (hit time2 + miss rate2 * miss penalty2)</li>
</ul>
</li>
</ul>
</li>
<li><p>actual CPI : cpu time divide into 2 parts</p>

<ul>
<li>cpu execution clock cycles</li>
<li>memory stall clock cycles

<ul>
<li>(instruction / program)* <strong>(misses/introduction)</strong> * miss penalty</li>
</ul>
</li>
<li>miss penalty = main memory access time / clock cycle</li>
<li>Effective CPI = bass CPI + L1 Miss rate * L2 Hit Time + L2 global miss rate * L2 Miss time</li>
<li>AMAT = L1 Hit time + L1 miss rate * L2 Hit time + L2 global miss rate * L2 Miss time</li>
<li>performance = 慢的/快的</li>
<li>e.g

<ul>
<li>CPU base CPI = 1, clock rate = 4GHz</li>
<li>Miss rate / instruction = 2%</li>
<li>Main memory access time = 100ms

<ul>
<li>then if there is only primary memory

<ul>
<li>Miss penalty = 100ns / clock cycle</li>
<li>clock cycle = 1/clock rate = 0.25

<ul>
<li>Miss penalty = 400 cycle</li>
</ul>
</li>
<li>Effective CPI = 1 + 2% * 400 = 9 cycle</li>
</ul>
</li>
</ul>
</li>
<li>then suppose we add L-2 cache

<ul>
<li>L2 cache access time = 5ns</li>
<li>L2 global miss rate = 0.5%

<ul>
<li>L2 Hit time = 5ns / clock cycle = 5ns / 0.25 = 20 cycles</li>
<li>L2 Miss time = 400 cycles</li>
<li>Effective CPI = 1 + 2% * 20 + 0.5% * 400 = 3.4 cycle</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>E.g. on a machine with one or two level caches</p></li>
<li>3 formulas (two from lectures, one from the HW 6 solution)</li>
</ul>
</li>
<li><p>Know what is LRU(least recent use) replacement policy</p></li>
<li>Virtual memory

<ul>
<li>1K = 2<sup>10</sup>

<ul>
<li>1K * 1K = 1M</li>
</ul>
</li>
<li>What is page table

<ul>
<li>用来在物理内存里面找一个页的</li>
<li>PTE:page table entries

<ul>
<li>indexed by virtual page</li>
</ul>
</li>
<li>如果page不在内存里面

<ul>
<li>PTE存物理page的数字</li>
</ul>
</li>
<li>如果page在内存里面

<ul>
<li>PTE refer to一个磁盘的位置</li>
</ul>
</li>
<li>dirty bit set to 1 当一个page被改动过</li>
</ul>
</li>
<li>Address subdivision</li>
<li>How to translate a virtual address to a physical address

<ul>
<li>CPU and OS translate virtual address to physical address</li>
<li>The CPU sends virtual address to MMU</li>
<li>The MMU send physical address to the memory</li>
</ul>
</li>
<li>Purpose of MMU

<ul>
<li>转换虚拟地址和物理地址</li>
</ul>
</li>
<li>What is page fault

<ul>
<li>其实相当于cache miss</li>
<li>当你有一个page fault，这个page就要被fetch from磁盘到内存</li>
<li>如何减少page fault？

<ul>
<li>全关联placement</li>
<li>小页面替换算法</li>
</ul>
</li>
</ul>
</li>
<li>How a page fault handler works?

<ul>
<li>use faulting virtual address to find PTE</li>
<li>locate page on disk</li>
<li>choose page to replace

<ul>
<li>if dirty, write the page to disk first</li>
</ul>
</li>
<li>read page into memory and update page table</li>
<li>make process runnable again

<ul>
<li>restart from faulting instruction</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>假设virtual address = 43 bits, page size = 4KB, PTE size = 4 byte</p>

<ul>
<li>那么对于单层 page table， 需要多少个PTES？

<ul>
<li>page size = 4KB = 2<sup>12</sup></li>
<li>那么最差要2<sup>43-12</sup></li>
</ul>
</li>
<li>那么需要存这个page table要多少物理内存？

<ul>
<li>2<sup>43-12</sup>*4 byte</li>
<li>2<sup>31</sup>*2<sup>2</sup> = 2<sup>33</sup></li>
</ul>
</li>
</ul>
</li>
<li><p>Know what is TLB</p>

<ul>
<li>Translate look-aside Buffer

<ul>
<li>TLB的miss由硬件或者软件控制</li>
<li>a spacial cache of page table entries within CPU</li>
</ul>
</li>
<li>Understand the interaction between TLB and caches

<ul>
<li>cache rage use physical address

<ul>
<li>need to translate before cache</li>
</ul>
</li>
</ul>
</li>
<li>TLB cache is a page table entries</li>
</ul>
</li>
<li><p>Know the sources of cache misses (3 Cs model) <strong>必考</strong></p>

<ul>
<li>三种类型的miss

<ul>
<li>compulsory miss

<ul>
<li>第一次访问会导致这种miss</li>
<li>因为第一次访问的时候数据不会在内存里面</li>
<li>解决方案

<ul>
<li>假设一个block只能存一个byte，然后我们要load 128 byte的数据

<ul>
<li>那么我们就要load 128次</li>
<li>但是如果把block增大成128 byte，那么我们只要存一次</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>capacity miss

<ul>
<li>理论上存在，实际的机器是不存在的</li>
<li>只有full associate cache</li>
<li>空间不足</li>
<li>解决方案

<ul>
<li>增大cache size</li>
</ul>
</li>
</ul>
</li>
<li>conflict miss

<ul>
<li>假设有两个entry，但是有100个要进去

<ul>
<li>这个时候就会发生这种miss</li>
</ul>
</li>
<li>也就是资源竞争</li>
<li>解决方案

<ul>
<li>增加关联性</li>
</ul>
</li>
<li>不存在于full associate cache</li>
</ul>
</li>
</ul>
</li>
<li>What about the fourth C?</li>
</ul>
</li>
<li><p>Software optimisation techniques: AVX, Loop Unrolling, Blocking?</p>

<ul>
<li>blocking

<ul>
<li>maximise accesses to data before it is replaced</li>
<li>应该就是访问数据之前，先把空间申请了</li>
</ul>
</li>
</ul>
</li>
<li><p>A few fallacies and pitfalls</p>

<ul>
<li><p>1.在多核CPU里里面，并且有shared的L2和L3cache</p>

<ul>
<li>如果关联性不够core多的话，会导致 conflict miss

<ul>
<li>e.g

<ul>
<li>如果有一个8核CPU，那么至少需要一个8-way的set 关联cache</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>2.用AMAT来评估一个out-of-order processor的性能</p>

<ul>
<li>忽略effect of non-blocking accesses(continuing execution on misses)</li>
<li>instead, evaluate performance by simulation</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>parallel processor</h3>

<ul>
<li>Amdahl&rsquo;s law

<ul>
<li>知道公式以及知道如何计算</li>
<li>公式

<ul>
<li>speedup = 1/[(1-F)+F/P]</li>
<li>F为并行化的百分比</li>
<li>P为处理器数量</li>
<li>e.g

<ul>
<li>我们有100个处理器，想要90倍的speedup</li>
<li>1/[(1-F) + F/100] = 90

<ul>
<li>F = 89*100/(99*90) = 99.9%</li>
<li>所以非并行的部分必须要&lt;=0.1%</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>strong scaling(缩放) and weak scaling

<ul>
<li><p>scaling</p>

<ul>
<li>e.g1 10*10 matrix

<ul>
<li>从10个处理器加速到100个处理器，speedup是多少

<ul>
<li>首先在单个处理器：time=(10+100)*Tadd=110*Tadd</li>
<li>10个处理器

<ul>
<li>time=10*Tadd + (10*10)/10*Tadd = 20*Tadd</li>
<li>speedup = 110/20=5.5</li>
</ul>
</li>
<li>100个处理器

<ul>
<li>time=10*Tadd + (10*10)/100*Tadd = 11*Tadd</li>
<li>speedup = 110/11 = 10</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>strong scaling</p>

<ul>
<li>数据规模确定</li>
</ul>
</li>
<li>weak scaling

<ul>
<li>数据规模和处理器的数量有关</li>
<li>例如

<ul>
<li>我们有10个处理器，那么数组的规模就是10*10</li>
<li>如果有100个处理器，那么数组的规模就是100*100</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>good understanding of hardware threading

<ul>
<li>增加单个核的资源利用率</li>
<li>在thread里面，dependency handled by scheduling and register renaming</li>
<li>不同的thread里面的指令在函数单元available 的时候执行</li>
<li>每个cycle都没有thread switching</li>
</ul>
</li>
</ul>

</div>


<div class="meta">
	<div class="date">








  


<time datetime="2015-05-04T22:07:15-05:00" pubdate data-updated="true">May 4<span>th</span>, 2015</time></div>
	

<div class="tags">

	<a class='category' href='/blog/categories/computer-architecture/'>computer_architecture</a>

</div>


	
		<span class="comments"><a href="/blog/2015/05/04/computer-architecture-final-exam-review/#disqus_thread">Comments</a></span>
	
</div></article>

	<div class="share">
	<div class="addthis_toolbox addthis_default_style ">
	
	
	
<!---	<a class="addthis_counter addthis_pill_style"></a> --->
	</div>
  <script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid="></script>
</div>



<section id="comment">
    <h2 class="title">Comments</h2>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2015

    pb

<br>
Powered by Octopress.
</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'pbking1';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://pbking1.github.com/blog/2015/05/04/computer-architecture-final-exam-review/';
        var disqus_url = 'http://pbking1.github.com/blog/2015/05/04/computer-architecture-final-exam-review/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>





</body>
</html>
