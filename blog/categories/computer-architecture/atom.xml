<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: computer_architecture | KING]]></title>
  <link href="http://pbking1.github.com/blog/categories/computer-architecture/atom.xml" rel="self"/>
  <link href="http://pbking1.github.com/"/>
  <updated>2016-02-12T13:31:02-06:00</updated>
  <id>http://pbking1.github.com/</id>
  <author>
    <name><![CDATA[pb]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[computer architecture final exam review]]></title>
    <link href="http://pbking1.github.com/blog/2015/05/04/computer-architecture-final-exam-review/"/>
    <updated>2015-05-04T22:07:15-05:00</updated>
    <id>http://pbking1.github.com/blog/2015/05/04/computer-architecture-final-exam-review</id>
    <content type="html"><![CDATA[<!--more-->


<h3>memory</h3>

<ul>
<li><p>Memory Hierarchy</p>

<ul>
<li>Understand what is memory wall? Why it is a bottleneck?瓶颈

<ul>
<li>内存壁垒：处理器和内存的悬殊持续增长</li>
<li>瓶颈：好的内存架构设计对系统的性能有越来越高的重要性</li>
</ul>
</li>
<li>Illusion provided from a memory hierarchy

<ul>
<li>大的内存都是很慢的，但是caching可以give 错觉他们很快</li>
<li>所以这个错觉可以是

<ul>
<li>caching + virtual memory 能够是的内存变快</li>
</ul>
</li>
<li>传统的内存层级

<ul>
<li>通过使用局部性的优势

<ul>
<li>能够尽可能的利用磁盘上能够使用的内存</li>
<li>速度也会很快</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Principle of locality (two types of locality)

<ul>
<li>定义:程序每次会使用一小部分的地址空间

<ul>
<li>temporal locality

<ul>
<li>曾经使用过的程序，再次被使用的可能会很大</li>
<li>比如循环中的指令和数据</li>
</ul>
</li>
<li>spatial locality

<ul>
<li>在执行过的程序附近的程序被使用的可能性很大</li>
<li>例如顺序执行中的数组</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>DDR RAM? Relationship between memory clock rate and memory bandwidth

<ul>
<li>mobile system require 2X bandwidth every 2 years</li>
</ul>
</li>
<li><p>DDR DRAM 叫double data rate DRAM</p>

<ul>
<li>transfer data on rising and falling clock edges</li>
<li>E.g., 800MHz DDR &ndash;> BW?</li>
</ul>
</li>
<li><p>Know how to calculate Average Disk Read Time</p>

<ul>
<li>average disk read time = seek time + rotation latency + transfer time + controller delay</li>
<li>rpm = revolution per minutes</li>
<li>e.g

<ul>
<li>512B sector, 15000rpm, 4ms average seek time, 100MB/s transfer rate, 0.2ms controller overhead, idle disk</li>
<li> time = 4ms seek time +

<ul>
<li>(&frac12;)/(15000/60) = 2ms rotationl latency</li>
<li>512/100MB/s = 5.12 s = 0.00512ms transfer time</li>
<li>0.2ms controller delay</li>
<li>= 6.2 ms</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Difference between three types of caches:</p>

<ul>
<li><strong>Direct-mapped cache</strong>

<ul>
<li>根据索引表映射哪个cache块用来存数据</li>
<li>一个block只能有一个选择存哪里</li>
<li>内存块的那一个位置分配给cache的某个位置，由后三位决定（假设有8个块（2<sup>3</sup>=8））

<ul>
<li>001：00001，01001，10001，11001</li>
</ul>
</li>
<li>用valid bit来判断cache的数据<strong>是否存在</strong>内存那个位置</li>
<li>tag用来判断cache的数据在内存哪个位置</li>
<li><strong>重点</strong>

<ul>
<li>index不存在cache里面，就像数组不会存索引</li>
<li>假设有一个word：22

<ul>
<li>首先转成二进制10110</li>
<li>然后后三位位index</li>
<li>前两位为tag</li>
<li>然后把数据存入对应位置</li>
<li>因为没存进来的时候，对应位置没有数据，所以为miss（第一次访问那个内存地址），存入之后，才会变成hit</li>
<li>然后数据valid bit变成Y</li>
</ul>
</li>
</ul>
</li>
<li> 假设一个cache有32 bit的地址

<ul>
<li> tag:22bits</li>
<li> index:4bits</li>
<li> offsets:6bits</li>
<li> 那么 cache block size 为2<sup>6</sup> byte</li>
<li> 那么 cache有2<sup>4</sup> entries</li>
</ul>
</li>
</ul>
</li>
<li>n-way Set-associative cache

<ul>
<li>每个set都有n个成员</li>
<li>用块的号数来决定哪个set</li>
<li>在给定的set中搜索全部成员（因为set里面的成员少，所以搜索起来快）

<ul>
<li>那么就只要比较n次，更加省时间</li>
</ul>
</li>
<li>假设一个cache有2<sup>s</sup>个sets， 并且每个block有2<sup>n</sup>个bytes。

<ul>
<li>那么block offset为n</li>
<li>index为s</li>
<li>假设address长度为m

<ul>
<li>则tag长度为m-s-n</li>
</ul>
</li>
<li>计算set index

<ul>
<li>block address = memory address / 2<sup>n</sup></li>
<li>set index = block address % 2<sup>s</sup></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Fully associative cache

<ul>
<li>cache可以映射到内存中任何一个位置</li>
<li>所有成员都要搜索一次</li>
<li>耗费时间长，每个成员都要对比, 每个block的tag都要对比</li>
</ul>
</li>
</ul>
</li>
<li>For each of the above cache type

<ul>
<li><p>How to calculate a block(or set) index give an address?</p>

<ul>
<li>miss: load 的数据不再memory里面

<ul>
<li>every miss always load the 64 byte</li>
</ul>
</li>
<li>如何选block size

<ul>
<li>用两种方式

<ul>
<li>early restart

<ul>
<li>CPU在等第一个byte，但是64byte还没load进去</li>
<li>或者可以先读第一个byte， 不用等他读完</li>
</ul>
</li>
<li>critical word first</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>How to subdivide an address given a cache design, or vice versa?</p></li>
</ul>
</li>
<li>Write back vs write through（write hit）

<ul>
<li>write through

<ul>
<li>如果write hit， 则更新缓存里面的block和memory里面的block</li>
<li>这样缓存和内存里面的数据就同步了</li>
<li>但是会使得数据的写更长时间

<ul>
<li>解决方案：使用write buffer

<ul>
<li>把要写入内存的数据hold waiting</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>write back</p>

<ul>
<li>当你更新数据的时候，只改cache里面的数据</li>
<li>速度快</li>
</ul>
</li>
<li><p>两者使用的差别</p>

<ul>
<li>如果写的频率高的时候，write back快</li>
</ul>
</li>
</ul>
</li>
<li>Write allocate vs no write allocate (on write miss)

<ul>
<li>allocate

<ul>
<li>fetch the block</li>
</ul>
</li>
<li>no allocate

<ul>
<li>do not fetch the block</li>
</ul>
</li>
</ul>
</li>
<li><p>condition</p>

<ul>
<li>if read hit: cpu continue</li>
<li>if write hit: write through or write back</li>
<li>if read miss: store pipeline, read data to pipeline and continue</li>
<li>if write miss: write through (allocate or no allocate)</li>
</ul>
</li>
<li><p>Know how to calculate AMAT, actual CPI</p>

<ul>
<li>AMAT: average memory access time

<ul>
<li>hit time + miss rate * miss penalty</li>
<li>如果是两层

<ul>
<li>AMAT = hit time1 + miss rate1 * (hit time2 + miss rate2 * miss penalty2)</li>
</ul>
</li>
</ul>
</li>
<li><p>actual CPI : cpu time divide into 2 parts</p>

<ul>
<li>cpu execution clock cycles</li>
<li>memory stall clock cycles

<ul>
<li>(instruction / program)* <strong>(misses/introduction)</strong> * miss penalty</li>
</ul>
</li>
<li>miss penalty = main memory access time / clock cycle</li>
<li>Effective CPI = bass CPI + L1 Miss rate * L2 Hit Time + L2 global miss rate * L2 Miss time</li>
<li>AMAT = L1 Hit time + L1 miss rate * L2 Hit time + L2 global miss rate * L2 Miss time</li>
<li>performance = 慢的/快的</li>
<li>e.g

<ul>
<li>CPU base CPI = 1, clock rate = 4GHz</li>
<li>Miss rate / instruction = 2%</li>
<li>Main memory access time = 100ms

<ul>
<li>then if there is only primary memory

<ul>
<li>Miss penalty = 100ns / clock cycle</li>
<li>clock cycle = 1/clock rate = 0.25

<ul>
<li>Miss penalty = 400 cycle</li>
</ul>
</li>
<li>Effective CPI = 1 + 2% * 400 = 9 cycle</li>
</ul>
</li>
</ul>
</li>
<li>then suppose we add L-2 cache

<ul>
<li>L2 cache access time = 5ns</li>
<li>L2 global miss rate = 0.5%

<ul>
<li>L2 Hit time = 5ns / clock cycle = 5ns / 0.25 = 20 cycles</li>
<li>L2 Miss time = 400 cycles</li>
<li>Effective CPI = 1 + 2% * 20 + 0.5% * 400 = 3.4 cycle</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>E.g. on a machine with one or two level caches</p></li>
<li>3 formulas (two from lectures, one from the HW 6 solution)</li>
</ul>
</li>
<li><p>Know what is LRU(least recent use) replacement policy</p></li>
<li>Virtual memory

<ul>
<li>1K = 2<sup>10</sup>

<ul>
<li>1K * 1K = 1M</li>
</ul>
</li>
<li>What is page table

<ul>
<li>用来在物理内存里面找一个页的</li>
<li>PTE:page table entries

<ul>
<li>indexed by virtual page</li>
</ul>
</li>
<li>如果page不在内存里面

<ul>
<li>PTE存物理page的数字</li>
</ul>
</li>
<li>如果page在内存里面

<ul>
<li>PTE refer to一个磁盘的位置</li>
</ul>
</li>
<li>dirty bit set to 1 当一个page被改动过</li>
</ul>
</li>
<li>Address subdivision</li>
<li>How to translate a virtual address to a physical address

<ul>
<li>CPU and OS translate virtual address to physical address</li>
<li>The CPU sends virtual address to MMU</li>
<li>The MMU send physical address to the memory</li>
</ul>
</li>
<li>Purpose of MMU

<ul>
<li>转换虚拟地址和物理地址</li>
</ul>
</li>
<li>What is page fault

<ul>
<li>其实相当于cache miss</li>
<li>当你有一个page fault，这个page就要被fetch from磁盘到内存</li>
<li>如何减少page fault？

<ul>
<li>全关联placement</li>
<li>小页面替换算法</li>
</ul>
</li>
</ul>
</li>
<li>How a page fault handler works?

<ul>
<li>use faulting virtual address to find PTE</li>
<li>locate page on disk</li>
<li>choose page to replace

<ul>
<li>if dirty, write the page to disk first</li>
</ul>
</li>
<li>read page into memory and update page table</li>
<li>make process runnable again

<ul>
<li>restart from faulting instruction</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>假设virtual address = 43 bits, page size = 4KB, PTE size = 4 byte</p>

<ul>
<li>那么对于单层 page table， 需要多少个PTES？

<ul>
<li>page size = 4KB = 2<sup>12</sup></li>
<li>那么最差要2<sup>43-12</sup></li>
</ul>
</li>
<li>那么需要存这个page table要多少物理内存？

<ul>
<li>2<sup>43-12</sup>*4 byte</li>
<li>2<sup>31</sup>*2<sup>2</sup> = 2<sup>33</sup></li>
</ul>
</li>
</ul>
</li>
<li><p>Know what is TLB</p>

<ul>
<li>Translate look-aside Buffer

<ul>
<li>TLB的miss由硬件或者软件控制</li>
<li>a spacial cache of page table entries within CPU</li>
</ul>
</li>
<li>Understand the interaction between TLB and caches

<ul>
<li>cache rage use physical address

<ul>
<li>need to translate before cache</li>
</ul>
</li>
</ul>
</li>
<li>TLB cache is a page table entries</li>
</ul>
</li>
<li><p>Know the sources of cache misses (3 Cs model) <strong>必考</strong></p>

<ul>
<li>三种类型的miss

<ul>
<li>compulsory miss

<ul>
<li>第一次访问会导致这种miss</li>
<li>因为第一次访问的时候数据不会在内存里面</li>
<li>解决方案

<ul>
<li>假设一个block只能存一个byte，然后我们要load 128 byte的数据

<ul>
<li>那么我们就要load 128次</li>
<li>但是如果把block增大成128 byte，那么我们只要存一次</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>capacity miss

<ul>
<li>理论上存在，实际的机器是不存在的</li>
<li>只有full associate cache</li>
<li>空间不足</li>
<li>解决方案

<ul>
<li>增大cache size</li>
</ul>
</li>
</ul>
</li>
<li>conflict miss

<ul>
<li>假设有两个entry，但是有100个要进去

<ul>
<li>这个时候就会发生这种miss</li>
</ul>
</li>
<li>也就是资源竞争</li>
<li>解决方案

<ul>
<li>增加关联性</li>
</ul>
</li>
<li>不存在于full associate cache</li>
</ul>
</li>
</ul>
</li>
<li>What about the fourth C?</li>
</ul>
</li>
<li><p>Software optimisation techniques: AVX, Loop Unrolling, Blocking?</p>

<ul>
<li>blocking

<ul>
<li>maximise accesses to data before it is replaced</li>
<li>应该就是访问数据之前，先把空间申请了</li>
</ul>
</li>
</ul>
</li>
<li><p>A few fallacies and pitfalls</p>

<ul>
<li><p>1.在多核CPU里里面，并且有shared的L2和L3cache</p>

<ul>
<li>如果关联性不够core多的话，会导致 conflict miss

<ul>
<li>e.g

<ul>
<li>如果有一个8核CPU，那么至少需要一个8-way的set 关联cache</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>2.用AMAT来评估一个out-of-order processor的性能</p>

<ul>
<li>忽略effect of non-blocking accesses(continuing execution on misses)</li>
<li>instead, evaluate performance by simulation</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>parallel processor</h3>

<ul>
<li>Amdahl&rsquo;s law

<ul>
<li>知道公式以及知道如何计算</li>
<li>公式

<ul>
<li>speedup = 1/[(1-F)+F/P]</li>
<li>F为并行化的百分比</li>
<li>P为处理器数量</li>
<li>e.g

<ul>
<li>我们有100个处理器，想要90倍的speedup</li>
<li>1/[(1-F) + F/100] = 90

<ul>
<li>F = 89*100/(99*90) = 99.9%</li>
<li>所以非并行的部分必须要&lt;=0.1%</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>strong scaling(缩放) and weak scaling

<ul>
<li><p>scaling</p>

<ul>
<li>e.g1 10*10 matrix

<ul>
<li>从10个处理器加速到100个处理器，speedup是多少

<ul>
<li>首先在单个处理器：time=(10+100)*Tadd=110*Tadd</li>
<li>10个处理器

<ul>
<li>time=10*Tadd + (10*10)/10*Tadd = 20*Tadd</li>
<li>speedup = 110/20=5.5</li>
</ul>
</li>
<li>100个处理器

<ul>
<li>time=10*Tadd + (10*10)/100*Tadd = 11*Tadd</li>
<li>speedup = 110/11 = 10</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>strong scaling</p>

<ul>
<li>数据规模确定</li>
</ul>
</li>
<li>weak scaling

<ul>
<li>数据规模和处理器的数量有关</li>
<li>例如

<ul>
<li>我们有10个处理器，那么数组的规模就是10*10</li>
<li>如果有100个处理器，那么数组的规模就是100*100</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>good understanding of hardware threading

<ul>
<li>增加单个核的资源利用率</li>
<li>在thread里面，dependency handled by scheduling and register renaming</li>
<li>不同的thread里面的指令在函数单元available 的时候执行</li>
<li>每个cycle都没有thread switching</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[computer architecture 1]]></title>
    <link href="http://pbking1.github.com/blog/2015/02/13/computer-architecture-1/"/>
    <updated>2015-02-13T13:28:43-06:00</updated>
    <id>http://pbking1.github.com/blog/2015/02/13/computer-architecture-1</id>
    <content type="html"><![CDATA[<h3>charpter1</h3>

<ul>
<li><p>What is computer architecture</p>

<ul>
<li>4 classes of computers

<ul>
<li>personal computer</li>
<li>server computer</li>
<li>embedded computer</li>
<li>supercomputer
<!--more--></li>
</ul>
</li>
<li><p>What does “PostPC era” mean</p>

<ul>
<li>personal mobile device(PMD)</li>
<li>cloud computing

<ul>
<li>server are replace by cloud computing</li>
<li>Software as a Service(Saas)</li>
</ul>
</li>
<li>Portion of software run on a PMD, and a portion(part of) run in the cloud</li>
</ul>
</li>
<li><p>What factors could affect performance</p>

<ul>
<li>algorithm</li>
<li>programming language, compiler, architecture</li>
<li>processor and memory system</li>
<li>I/O system(including OS and hardware)</li>
</ul>
</li>
<li><p>Eight great ideas – Know what they mean</p>

<ul>
<li>1.design for moore&rsquo;s law</li>
<li>2.use abstraction to simplify design</li>
<li>3.make the common case fast</li>
<li>4.performance via parallelism</li>
<li>5.performance via pipelining</li>
<li>6.performance via prediction</li>
<li>7.hierarchy of memory</li>
<li>8.dependability via redundancy</li>
</ul>
</li>
</ul>
</li>
<li><p>Different levels of program code</p>

<ul>
<li>HLL &ndash;> Assembly language &ndash;> ML</li>
<li>5 components of a computer

<ul>
<li>input</li>
<li>output</li>
<li>control

<ul>
<li>tells datapath, memory, I/O what to do according to the instructions.</li>
</ul>
</li>
<li>datapath

<ul>
<li>performs the arithmetic operations</li>
</ul>
</li>
<li>memory</li>
</ul>
</li>
<li><p>input &ndash;>(control, datapath)&ndash;>output</p></li>
<li><p>What is ISA?</p>

<ul>
<li>instruction set architecture

<ul>
<li>the hardware/software interface</li>
</ul>
</li>
</ul>
</li>
<li><p>Understand “Yield” in terms of chip manufacturing?</p>

<ul>
<li>Proportion of working dies per wafer晶圆(硅半导体集成电路制作所用的硅晶片)</li>
</ul>
</li>
<li><p>Response time vs Throughput</p>

<ul>
<li>Response time

<ul>
<li>How long it takes to do one task</li>
</ul>
</li>
<li>Throughput

<ul>
<li>Total work done per unit time</li>
</ul>
</li>
</ul>
</li>
<li><p>Elapsed time vs CPU time</p>

<ul>
<li>elapsed time

<ul>
<li>wall clock time

<ul>
<li>total response time, inkling everything</li>
<li>can be used to determine the system performance</li>
</ul>
</li>
</ul>
</li>
<li>cpu time

<ul>
<li>the time that cpu spent for <strong>a given process</strong></li>
<li>can be divide into user CPU time and system CPU time</li>
</ul>
</li>
</ul>
</li>
<li><p>Know how to calculate CPU time, CPI_avg, IPC, Clock rate, Clock Cycle Time, and Performance</p>

<ul>
<li>1 cycle per second &ndash;> 1 Hz

<ul>
<li>1 GHz = 10<sup>9</sup> hz</li>
</ul>
</li>
<li>clock rate(frequency)

<ul>
<li>cycle per second</li>
</ul>
</li>
<li>clock cycle time(period)

<ul>
<li>duration of a clock cycle</li>
</ul>
</li>
<li>CPU time

<ul>
<li>CPU time = CPU clock cycle * clock cycle time = CPU Clock cycle / Clock Rate</li>
</ul>
</li>
<li>Instruction count

<ul>
<li>determine by program, ISA, compiler</li>
</ul>
</li>
<li>Average cycle per instruction(CPI)

<ul>
<li>IPC = 1/CPI</li>
</ul>
</li>
<li>Clock Cycle = Instruction * Average Cycle per instruction</li>
<li>CPU time = Instruction * CPI * Clock Cycle Time

<ul>
<li>= Instruction Count * CPI / Clock Rate</li>
<li>= Instruction Count / (Clock Rate * IPC)</li>
<li>= (Instruction/program) * (Cycles/Instruction) * (Seconds/Cycle)</li>
<li>= IC * PCI * CC</li>
</ul>
</li>
<li>Clock Cycles = sum(CPI * Instruction Count)</li>
<li>how to measure performance

<ul>
<li>use instruction/second

<ul>
<li>so we can use the format clock rate/CPI</li>
</ul>
</li>
</ul>
</li>
<li>Performance depends on

<ul>
<li>Algorithm:affects IC, CPI</li>
<li>programming language: affects IC, CPI</li>
<li>Compiler:affects IC, CPI</li>
<li>ISA:affects IC, CPI, CC</li>
</ul>
</li>
<li>if you want an improvement in the execution time

<ul>
<li>you need to deduce the percentage of old time

<ul>
<li>for example

<ul>
<li>if you want to improve 50%, then you should use (100%-50%)=50% rather than (100% + 50%) = 150%</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>speed up

<ul>
<li>use the (old execute time) / (new execute time)

<ul>
<li>old time = old instruction count * old average cycle per instruction / clock rate</li>
<li>new time = new instruction count * new average cycle per instruction / clock rate

<ul>
<li>old time / new time = old instruction count * old average cycle per instruction / (new instruction count * new average cycle per instruction)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Could explain why “Power Wall” is a problem?</p>

<ul>
<li><p>situation</p>

<ul>
<li>can not reduce voltage further, and will make transistor more leaky</li>
</ul>
</li>
<li><p>Power = Capacitive Load * Voltage * Frequency</p></li>
<li><p>Understand what are the challenges on multicore processors</p>

<ul>
<li>Multicore processors: more than one core per chip</li>
<li>Hard to do

<ul>
<li>Programming for performance (not only for correctness)</li>
<li>Load balancing</li>
<li>Optimizing communication and synchronization</li>
</ul>
</li>
</ul>
</li>
<li><p>Fallacies and Pitfalls</p>

<ul>
<li>Fallacy: Some commonly held misconceptions that you might encounter

<ul>
<li>Computers at low utilization use little bit power</li>
<li>Designing for performance and designing for energy efficiency are unrelated</li>
</ul>
</li>
<li>PiGall: easily made mistakes

<ul>
<li> They are only true in a limited context</li>
<li>Can help you avoid making the same mistakes

<ul>
<li>example:

<ul>
<li>If you improve one aspect of a computer, then you would expect a proportional improvement in the overall performance</li>
<li>Using a subset of the performance equal on as a performance metric.</li>
<li>MIPS as a Performance Metric</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>e.g. MIPS, Amdahl’s Law, etc.</p></li>
</ul>
</li>
</ul>


<h3>chapter 2</h3>

<ul>
<li>Understand what is instruction and instruction set?

<ul>
<li>instruction set: the vocabulary of all commands understood

<ul>
<li>different computer have different instruction set</li>
</ul>
</li>
<li>instruction: words of computer&rsquo;s language</li>
<li>instruction set architecture(ISA): ISA serves as the interface between software and hardware

<ul>
<li>provide the mechanism by which software tells hardware what should be done</li>
</ul>
</li>
</ul>
</li>
<li>Differences between RISC and CISC

<ul>
<li>RISC

<ul>
<li>reduced instruction set computer</li>
<li>difference

<ul>
<li>fixed instruction lengths 32 bits</li>
<li>load store instruction sets</li>
<li>limited addressing modes</li>
<li>limited operations</li>
<li>simpler, cheaper</li>
<li>MIPS: typical of RISC ISAs</li>
</ul>
</li>
</ul>
</li>
<li>CISC

<ul>
<li>x86</li>
</ul>
</li>
</ul>
</li>
<li><p>MIPS ISA</p>

<ul>
<li><p>MIPS has a number 32 32-bit registers</p>

<ul>
<li>32 bit data called a word</li>
<li>memory is byte addressed

<ul>
<li>each address identifies a byte</li>
</ul>
</li>
<li>MIPS is big endian</li>
</ul>
</li>
<li><p>R and I types of instruction format</p>

<ul>
<li>R-format

<ul>
<li><code>op(6 bits)-rs(5 bits)-rt(5 bits)-rd(5 bits)-shamt(5 bits)-funct(6 bits)</code></li>
<li>add, sub</li>
</ul>
</li>
<li>I-format

<ul>
<li><code>op(6 bits)-rs(5 bits)-rt(5 bits)-constant or offset address(16 bits)</code></li>
<li>addi, lw, sw, beq, bne</li>
</ul>
</li>
</ul>
</li>
<li><p>Big endian, little endian</p>

<ul>
<li>little endian: <strong>least</strong> significant byte store at least-address of memory</li>
<li>big endian: <strong>Most</strong> significant byte store at least-address of memory</li>
</ul>
</li>
<li> Memory alignment

<ul>
<li>although computer are byte-addressable</li>
<li>memory typically organised in n-byte lines</li>
<li><strong>only the char[N] are the same in both big endian and little endian</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>How to represent unsigned and signed integers</p>

<ul>
<li>What is 2s-complement, how, why

<ul>
<li>Most-negative: 1000 0000 &hellip; 0000</li>
<li>Most-positive: 0111 1111 &hellip; 1111</li>
<li>Bit 31 is called “sign bit”</li>
<li>求负：取反加一</li>
</ul>
</li>
</ul>
</li>
<li><p>Sign extension</p>

<ul>
<li>leading bit = 1 &ndash;> negative</li>
<li>range

<ul>
<li>–2,147,483,648t o +2,147,483,647</li>
</ul>
</li>
<li>Sign extension: replicate the sign bit to the left</li>
<li>2<sup>31</sup> &ndash; 1 = 0x7FFFFFFF</li>
<li>-2<sup>31</sup> = 0x80000000</li>
<li>overflow problem

<ul>
<li>for add instruciton

<ul>
<li>128 + x > 2<sup>31</sup> &ndash; 1 the upper bound</li>
<li>128 + x &lt; -2<sup>31</sup> the lower bound</li>
</ul>
</li>
<li>so if you want to overflow, you need to bigger than 2<sup>31</sup> &ndash; 1 and smaller than -2<sup>31</sup></li>
</ul>
</li>
</ul>
</li>
<li><p>Logical operations: sll, srl, and, or, nor</p></li>
<li><p>Conditional operations: beq, bne</p>

<ul>
<li>beq: branch equal</li>
<li>bne: branch not equal</li>
</ul>
</li>
<li><p>Concept of “basic block”</p>

<ul>
<li>a basic block is a sequence of instructions with no embedded branch, no branch target</li>
</ul>
</li>
<li><p>How “Procedure calling” is supported</p>

<ul>
<li>procedure is used to structure program</li>
<li>each procedure performs a specific task</li>
<li>working like a black box</li>
</ul>
</li>
<li><p>Know jal (for calling), and jr (for return)</p>

<ul>
<li>jal procedureName

<ul>
<li>puts address of following instruction in $ra</li>
<li>jump to target address</li>
<li>procedure call</li>
</ul>
</li>
<li>jr $ra

<ul>
<li>jump-register</li>
<li>copy $ra to PC</li>
<li>procedure return</li>
</ul>
</li>
</ul>
</li>
<li><p>Understand the fact(n) assembly example</p></li>
<li><p>The memory layout of a program</p></li>
<li><p>J-type instruction format, e.g., j and jal</p>

<ul>
<li><code>op(6 bits)-instruction address(26 bits)</code></li>
</ul>
</li>
<li><p>Know how to calculate the target of PC-relative addressing, and target of (pseudo) direct jump addressing</p>

<ul>
<li>target address = PC + offset * 4</li>
<li>pseudo instructions: not real instruction

<ul>
<li>move $t0, $t1 &ndash;> add $t0, $zero, $t1</li>
<li>blt $t0, $t1, L &ndash;> slt $at, $t0, $t1

<ul>
<li> bne $at, $zero, L</li>
</ul>
</li>
<li>$at : assembler temporary</li>
</ul>
</li>
</ul>
</li>
<li><p>Hardware synchronisation instructions</p>

<ul>
<li><p>ll rt, offset(rs)</p>

<ul>
<li>load linked</li>
</ul>
</li>
<li><p>sc rt, offset(rs)</p>

<ul>
<li>store conditional</li>
</ul>
</li>
<li>rt is both input and output</li>
</ul>
</li>
<li><p>Know what information is stored in object modules</p>

<ul>
<li>the assembler translate program into <strong>machine instructions</strong> which are stored in object modules</li>
</ul>
</li>
<li><p>Know what are Compiler, Assembler, Linker, Loader used for?</p>

<ul>
<li>C program compile through compiler</li>
<li>the compiler come up with assembly language program</li>
<li>then assembler generate object(Machine language module)</li>
<li>object(machine language module and library routine) go to linker</li>
<li>the linker static link and generate executable machine language program</li>
<li>then go to loader and load into memory</li>
</ul>
</li>
<li><p>A few fallacies and pithalls</p>

<ul>
<li>instruction count and CPI are not good performance indicators in isolation</li>
<li>compiler optimisation are sensitive to algorithm</li>
<li>java compiled code s significantly faster than JVM interpreted</li>
<li>nothing can fix a dumb algorithm</li>
<li>use assembly code for high performance</li>
<li>powerful instruction &ndash;> high performance</li>
<li>importance of binary compatibility => instruction set does not change</li>
<li>sequential words are at sequential byte addresses

<ul>
<li>increment by 4</li>
</ul>
</li>
<li>using a pointer to an automatic variable outside its defining procedure

<ul>
<li>e.g passing pointer back via returning result

<ul>
<li>because pointer becomes invalid when stack popped</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>MIPS instruction</p></li>
<li><table>
<thead>
<tr>
<th>MIPS instructions </th>
<th> Name </th>
<th> format</th>
</tr>
</thead>
<tbody>
<tr>
<td>add</td>
<td>add</td>
<td>R</td>
</tr>
<tr>
<td>subtract</td>
<td>sub</td>
<td>R</td>
</tr>
<tr>
<td>add immediate</td>
<td>addi</td>
<td>I</td>
</tr>
<tr>
<td>load word</td>
<td>lw</td>
<td>I</td>
</tr>
<tr>
<td>store word </td>
<td> sw </td>
<td> I</td>
</tr>
<tr>
<td>load half </td>
<td> lh </td>
<td> I</td>
</tr>
<tr>
<td>load half unsigned </td>
<td> lhu </td>
<td> I</td>
</tr>
<tr>
<td>store half </td>
<td> sh </td>
<td> I</td>
</tr>
<tr>
<td>load byte </td>
<td> lb </td>
<td>  I </td>
</tr>
<tr>
<td>load byte unsigned</td>
<td> lbu </td>
<td> I</td>
</tr>
<tr>
<td>store byte </td>
<td> sb </td>
<td> I</td>
</tr>
<tr>
<td>load linked </td>
<td> ll </td>
<td> I</td>
</tr>
<tr>
<td>store conditional </td>
<td> sc </td>
<td> I</td>
</tr>
<tr>
<td>load upper immediate </td>
<td> lui </td>
<td> I</td>
</tr>
<tr>
<td>and </td>
<td> and </td>
<td> R</td>
</tr>
<tr>
<td>or </td>
<td> or </td>
<td> R</td>
</tr>
<tr>
<td>nor </td>
<td> nor </td>
<td> R</td>
</tr>
<tr>
<td>and immediate </td>
<td> andi </td>
<td> I</td>
</tr>
<tr>
<td>or immediate </td>
<td> ori </td>
<td> I</td>
</tr>
<tr>
<td>shift left logical </td>
<td> all </td>
<td> R</td>
</tr>
<tr>
<td>shift right logical </td>
<td> srl </td>
<td> R</td>
</tr>
<tr>
<td>branch on equal </td>
<td> beq </td>
<td> I</td>
</tr>
<tr>
<td>branch on not equal </td>
<td> bne </td>
<td> I</td>
</tr>
<tr>
<td>set less than </td>
<td> slt </td>
<td> R</td>
</tr>
<tr>
<td>set less than immediate  </td>
<td> slti </td>
<td> I</td>
</tr>
<tr>
<td>set less than immediate unsigned</td>
<td> sltiu </td>
<td> I</td>
</tr>
<tr>
<td>jump </td>
<td> j </td>
<td> J</td>
</tr>
<tr>
<td>jump register </td>
<td> jr </td>
<td> R</td>
</tr>
<tr>
<td>jump and link </td>
<td> jal </td>
<td> J</td>
</tr>
</tbody>
</table>
</li>
<li><p>thus we can see that R instruction contain the kind</p>

<ul>
<li>add, sub, and, or , nor, slt, shift, jump register, move, multi</li>
</ul>
</li>
<li>the I instruction contain

<ul>
<li>contain the load, store, immediate command, branch</li>
</ul>
</li>
<li><p>J instruction only have j and jal</p></li>
<li><p>汇编代码示例</p>

<ul>
<li>1.<code>if (i == j) f = g + h; else f = g - h</code>

<ul>
<li>beq $s3, $s4, Then</li>
<li>sub $s0, $s1, $s2</li>
<li>J Exit</li>
<li>Then: add $s0, $s1, $s2</li>
<li>Exit: &hellip;</li>
</ul>
</li>
<li>2.<code>while(array[i] == k) i+=1</code>

<ul>
<li>Loop:sll $t1, $s3, 2 //t1 = i * 4</li>
<li>add $t1, $t1, $s6</li>
<li>lw $t0, $t1</li>
<li>beq $s5, $t0, EXIT</li>
<li>addi $s3, $s3, 1</li>
<li>j Loop</li>
<li>EXIT:&hellip;</li>
</ul>
</li>
<li><p>3.leaf procedure example</p>

<ul>
<li><p><code>
int leaf_example(int, g, h, i, j){
  int f;
  f = (g + h) - (i - j);
  return f;
}
</code></p></li>
<li><p>MIPS code:</p>

<ul>
<li>addi $sp, $sp, -4  //save s0 on stack</li>
<li>sw $s0, 0($sp)</li>
<li>add $t0, $a0, $a1</li>
<li>add $t1, $a2, $a3</li>
<li>sub $s0, $t0, $t1</li>
<li>add $v0, $s0, $zero   //store result</li>
<li>lw $s0, 0($sp)   //store s0</li>
<li>addi $sp, $sp, 4</li>
<li>jr $ra  //return</li>
</ul>
</li>
</ul>
</li>
<li><p> 4.no leaf procedure example</p>

<ul>
<li><p> <code>
int fact(int n){
   if(n &lt; 1){
       return 1;
   }else{
       return n * fact(n - 1);
   }
}
int main(){
   int n = 10;
   fact(n);
   printf(n);
}
</code></p></li>
<li><p> MIPS code:</p>

<ul>
<li> fact:

<ul>
<li>addi $sp, $sp, -8</li>
<li>lw $ra, 4($sp)</li>
<li>lw $a0, 0($sp)</li>
<li>slti $t0, $a0, 1  //n &lt; 1, t0 = 1</li>
<li>beq $t0, $zero, L1 //if t0 == 0(means n >= 1) go to L1</li>
<li>addi $v0, $zer0, 1</li>
<li>addi $sp, $sp, 8</li>
<li>jr $ra //return address</li>
</ul>
</li>
<li> L1:

<ul>
<li>addi $a0, $a0, -1 //n = n &ndash; 1</li>
<li>jal fact //递归</li>
<li>sw $a0, 0($sp)</li>
<li>sw $ra, 4($sp)</li>
<li>addi $sp, $sp, 8</li>
<li>multi $v0, $a0, $v0 //n*fact(n-1)</li>
<li>jr $ra  //return address</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>segment place</p>

<ul>
<li>code segment &ndash;> data segment &ndash;> heap segment &ndash;> stack segment

<h3>chapter 3</h3></li>
</ul>
</li>
<li><p>Given a logic function, know how to draw its logic gate diagram</p></li>
<li><p>Given a logic gate diagram, know how to write down its logic function</p></li>
<li>Know how a full adder is implemented</li>
<li>Know what are decoder and multiplexer and how they work</li>
<li>Understand clock, register, SRAM, DRAM

<ul>
<li>SRAM:static Random Access Memory</li>
<li>DRAM:dynamic Random Access Memory</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
