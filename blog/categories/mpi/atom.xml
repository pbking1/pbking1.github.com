<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: mpi | KING]]></title>
  <link href="http://pbking1.github.com/blog/categories/mpi/atom.xml" rel="self"/>
  <link href="http://pbking1.github.com/"/>
  <updated>2016-02-12T13:29:13-06:00</updated>
  <id>http://pbking1.github.com/</id>
  <author>
    <name><![CDATA[pb]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[mpi_parallel_programming_2]]></title>
    <link href="http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-2/"/>
    <updated>2014-09-15T14:28:34-05:00</updated>
    <id>http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-2</id>
    <content type="html"><![CDATA[<h3>data type</h3>

<ul>
<li><p>there are only these data type in the MPI</p>

<ul>
<li>if you want to use struct or multi array, you need to do something else</li>
</ul>
</li>
<li><table>
<thead>
<tr>
<th></th>
<th>MPI data type</th>
<th> c data type</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>MPI_CHAR</td>
<td>signed char|</td>
</tr>
<tr>
<td></td>
<td>MPI_SHORT</td>
<td>signed short int|</td>
</tr>
<tr>
<td></td>
<td>MPI_INT</td>
<td>signed int|</td>
</tr>
<tr>
<td></td>
<td>MPI_LONG</td>
<td>signed long int|</td>
</tr>
<tr>
<td></td>
<td>MPI_UNSIGNED_CHAR</td>
<td>unsigned long int|</td>
</tr>
<tr>
<td></td>
<td>MPI_UNSIGNED_SHORT</td>
<td>unsigned short int|</td>
</tr>
<tr>
<td></td>
<td>MPI_UNSIGNED</td>
<td>unsigned int|</td>
</tr>
<tr>
<td></td>
<td>MPI_FLOAT</td>
<td>float|</td>
</tr>
<tr>
<td></td>
<td>MPI_DOUBLE</td>
<td>double|</td>
</tr>
<tr>
<td></td>
<td>MPI_LONG_DOUBLE</td>
<td>long double|</td>
</tr>
<tr>
<td></td>
<td>MPI_BYTE</td>
<td>|</td>
</tr>
<tr>
<td></td>
<td>MPI_MPI_PACKED</td>
<td>|</td>
</tr>
</tbody>
</table>
</li>
</ul>


<!--more-->


<h3>about the status</h3>

<ul>
<li>the MPI_status combine a lots of information

<ul>
<li>there are at least three member in the status

<ul>
<li>MPI_SOURCE, MPI_TAG, MPI_ERROR</li>
</ul>
</li>
</ul>
</li>
<li>and we can get the size of the message using

<ul>
<li>MPI_Get_Count(MPI_Status <em>status, MPI_Datatype datatype, int</em> count_ptr);</li>
</ul>
</li>
</ul>


<h3>The broadcast idea</h3>

<ul>
<li>you can use the MPI_Bcast idea to send the message to all the other process;

<ul>
<li>MPI_Bcast(void *message, int count, MPI_Datatype datatype, int root, MPI_Comm comm)</li>
</ul>
</li>
</ul>


<h3>gather the data and scatter the data</h3>

<ul>
<li>use MPI_Gather

<ul>
<li>MPI_Gather(void <em>send_data, int send_count, MPI_Datatype send_type, void</em> recv_data, int recv_count, MPI_Datatype recv_type, int root, MPI_Comm comm)</li>
</ul>
</li>
<li>use MPI_Scatter to scatter the data

<ul>
<li>MPI_Scatter(void <em>send_data, int send_count, MPI_Datatype send_type, void </em>recv_data, int recv_count, MPI_Datatype recv_type, int root, MPI_Comm comm);</li>
<li>MPI_Scatter split the data referenced by send_data on the process with rank root into k segment.each of which consists of send_count elements of type send_type.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mpi_parallel_programming_1]]></title>
    <link href="http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-1/"/>
    <updated>2014-09-15T13:19:13-05:00</updated>
    <id>http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-1</id>
    <content type="html"><![CDATA[<h3>difference between SIMD and MIMD</h3>

<ul>
<li>difference kinds of computer architecture is using the Flynn to classify

<ul>
<li>SISD</li>
<li>SIMD</li>
<li>MISD</li>
<li>MIMD</li>
</ul>
</li>
<li>we only talk about the SIMD and MIMD here

<ul>
<li>SIMD means that one command deal with many data streams

<ul>
<li>most of the single core machine is SIMD machine</li>
<li>and these kinds of machine is most used in the image processing and multimedia processing.</li>
</ul>
</li>
</ul>
</li>
</ul>


<!--more-->


<pre><code>- MIMD means that many commands deal with many data streams
    - the lastest multicore platform is a MIMD machine
    - the MIMD are asynchronous
    - 
</code></pre>

<h4>the multi core hardware architecture</h4>

<ul>
<li>the multicore CPU is combine many CPU into one chip. and each CPU core has a single processor.

<ul>
<li>each core has it&rsquo;s own cache. (some other may share one cache between multi CPU)</li>
</ul>
</li>
</ul>


<h3>message passing</h3>

<ul>
<li>There are two methods in the message passing

<ul>
<li>MPI_Send

<ul>
<li>void * buffer, int count, MPI_Datatype datatype, int destination, int tag, MPI_Comm communicator</li>
<li>e.g

<ul>
<li>MPI_Send(&amp;x, 1, MPI_FLOAT, 1, 0, MPI_COMM_WORLD);</li>
</ul>
</li>
</ul>
</li>
<li>MPI_Recv

<ul>
<li>void * buffer, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm communicator, MPI_Status status</li>
<li>MPI_Recv(&amp;x, 1, MPI_FLOAT, 0, 0, MPI_COMM_WORLD, &amp;status);</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>sample program</h3>

<p>```</p>

<h1>include &ldquo;mpi.h&rdquo;</h1>

<p>int main(int argc, char *argv[]){</p>

<pre><code>int rank; //rank of the process
int source; //rank of the sender
int dest;   //rank of the receiver
int num;    //number of the processers
int tags;
char messages[1000];
MPI_Status status;

//setting up the MPI
MPI_init(&amp;argc, &amp;argv);

//find out the rank of the curret program
MPI_Comm_rank(MPI_COMM_WORLD, rank);

//find out the number of the processers
MPI_Common_Size(MPI_COMM_WORLD, &amp;p);

if(rank != 0){ //if the current program is not the root program
    sprintf(message, "hello from %d", rank);
    dest = 0;
    MPI_Send(message, strlen(message) + 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);
}else{
    sprintf(message, "hello from ");
    MPI_Recv(message, 100, MPI_CHAR, source, tag, MPI_COMM_WORLD, &amp;status);
    printf("%s\n", message);
}
MPI_Finalize();
</code></pre>

<p>}</p>

<p>```</p>

<h3>how to run the program</h3>

<ul>
<li>for c++

<ul>
<li><code>mpic++ -o test test.cpp</code></li>
</ul>
</li>
<li>for c

<ul>
<li><code>mpicc -o test test.c</code></li>
</ul>
</li>
<li>run

<ul>
<li>for m core computer

<ul>
<li><code>mpirun -np m test</code></li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
