<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Algorithm | KING]]></title>
  <link href="http://pbking1.github.com/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://pbking1.github.com/"/>
  <updated>2014-05-25T15:07:25+08:00</updated>
  <id>http://pbking1.github.com/</id>
  <author>
    <name><![CDATA[pb]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Intro to Recommandation System]]></title>
    <link href="http://pbking1.github.com/blog/2014/05/24/intro-to-recommandation-system/"/>
    <updated>2014-05-24T10:32:15+08:00</updated>
    <id>http://pbking1.github.com/blog/2014/05/24/intro-to-recommandation-system</id>
    <content type="html"><![CDATA[<ul>
<li>Problem formulation

<ul>
<li>可能会有99%的数据是不知道的（用问号表示）</li>
<li>因此可以去猜那些不知道的数据是多少</li>
<li>然后把得分最高的电影推荐给他就可以了</li>
<li>所以其实是一个矩阵补全系统</li>
</ul>
</li>
</ul>


<!--more-->


<ul>
<li><p>基于人口统计学的推荐系统</p>

<ul>
<li>最简单的一种，只是根据系统用户的基本信息发现用户的相关程度，然后把相似用户喜爱的其他用品推荐给当前用户。</li>
<li>系统首先会根据用户的属性建模，比如用户的年龄，性别，兴趣等信息。根据这些特征计算用户间的相似度。比如系统通过计算发现用户A和C比较相似。就会把A喜欢的物品推荐给C。

<ul>
<li>优势

<ul>
<li>不需要历史数据，没有冷启动问题</li>
<li>不依赖于物品的属性，因此其他领域的问题都可无缝接入。</li>
</ul>
</li>
<li>不足：

<ul>
<li>算法比较粗糙，效果很难令人满意，只适合简单的推荐</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>content based recommender system(基于内容)</p>

<ul>
<li>使用物品本身的相似度而不是用户的相似度。</li>
<li>e.g 通过相似度计算，发现电影A和C相似度较高，因为他们都属于爱情类。系统还会发现用户A喜欢电影A，由此得出结论，用户A很可能对电影C也感兴趣。于是将电影C推荐给A。</li>
<li>假设有一些别的特征例如电影的浪漫成都或者动作成分含量（由专家弄出来的）</li>
<li>因此可以把原有的评分作为输入，把专家的预测作为y

<ul>
<li>做线性回归， 把每个用户的theta学出来</li>
<li>然后把theta和用户的评分做内积，得出那些问号的数据</li>
</ul>
</li>
</ul>
</li>
<li><p>协同过滤</p>

<ul>
<li>基于物品的协同过滤

<ul>
<li>根本思想是

<ul>
<li>预先根据所有用户的历史偏好数据计算物品之间的相似性，然后把和用户喜欢的物品相类似的物品推荐给用户。</li>
<li>假设a和c很相近，因为喜欢a的用户同时也喜欢c，而用户A喜欢a，所以把c推荐给用户A</li>
</ul>
</li>
</ul>
</li>
<li><p>如何计算相似度</p>

<ul>
<li>基于余弦的相似度计算

<ul>
<li>通过计算两个向量之间的夹角的余弦值来计算物品之间的相似性</li>
</ul>
</li>
<li>基于关联的相似度计算

<ul>
<li>计算两个向量之间的Pearson-r关联度</li>
</ul>
</li>
<li>调整的余弦相似度计算

<ul>
<li>由于基于余弦的相似度计算没有考虑不同用户的打分情况，可能有的用户偏向于给低分，有的用户偏向于给高分，该方法通过减去用户的打分的平均值消除不同用户打分习惯的影响</li>
</ul>
</li>
</ul>
</li>
<li><p>其中一种实现</p>

<ul>
<li>1.建立物品的同现矩阵

<ul>
<li>也就是按照用户分组，找出每两个物品再多少个用户中同时出现的次数</li>
</ul>
</li>
<li>2.建立用户的评分矩阵

<ul>
<li>也就是每个用户对每个物品的评分</li>
</ul>
</li>
<li>3.两个矩阵相乘，计算结果</li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Perceptual Hash Algorithm in Objective C]]></title>
    <link href="http://pbking1.github.com/blog/2014/05/19/perceptual-hash-algorithm-in-objective-c/"/>
    <updated>2014-05-19T17:47:06+08:00</updated>
    <id>http://pbking1.github.com/blog/2014/05/19/perceptual-hash-algorithm-in-objective-c</id>
    <content type="html"><![CDATA[<h4>此文为借鉴阮一峰2011年和2013年发布的相似图片搜索原理</h4>

<ul>
<li>原文已经写得很好了，所以我只是把它整理了一下，学习学习~~</li>
</ul>


<h3>又名感知哈希算法</h3>

<ul>
<li>主要思想是

<ul>
<li>对每个图片生成一个“指纹”字符串，然后比较不同图片的指纹。结果越接近，就说明图片越相似</li>
</ul>
</li>
<li>这种算法的优点是简单快速，不收图片大小缩放的影响

<ul>
<li>缺点是图片内容不能变更。如果在图片上加几个文字，他就认不出来了</li>
</ul>
</li>
<li>因此最佳应用应该是根据缩略图找出原图</li>
</ul>


<!--more-->


<ul>
<li>算法样例

<ul>
<li>第一步 缩小尺寸

<ul>
<li>把图片缩小大8*8的尺寸，总共有64个像素。这一步的作用是去除图片的细节，只保留结构，明暗等基本信息，摒弃不同的尺寸，比例带来的图片差异</li>
</ul>
</li>
<li>第二步 简化色彩

<ul>
<li>将缩小之后的图片转为64级灰度。也就是说，所有的像素点总共之后64中颜色</li>
</ul>
</li>
<li>第三步 计算平均值

<ul>
<li>计算所有64个像素的灰度平均值</li>
</ul>
</li>
<li>第四步 比较像素的灰度

<ul>
<li>把每个像素的灰度，和平均值进行比较。大于或者等于平均值的，记为1；小于平均值，记为0；</li>
</ul>
</li>
<li>第五步 计算hash值

<ul>
<li>把上一步比较的结果，组合在一起，就构成一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片采用同样的次序就行了。</li>
<li>hash_value = 127ysje82ewrdfw3(16个数字)</li>
<li>这个值也就是指纹</li>
<li>得到指纹之后就可以对比不同的图片，看看64为中有多少位是不一样的。理论上，这等同与计算”汉明距离“。如果不相同的数据位不超过5，这就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>网上其他两种类似的算法</h3>

<h4>颜色分布法</h4>

<ul>
<li>每张图片都可以生成颜色分布的直方图。如果两种那个图片的直方图很接近，那么就可以认为他们很相似</li>
<li>由于任何一种颜色都是有红绿蓝三原色（RGB）构成的，所以可以画出四幅图（三原色直方图和最后合成的直方图）</li>
<li>如果每种原色都可以取256个值，那么整个颜色空间共有1600万种颜色（256的三次方）。针对这1600万种颜色比较直方图，计算量实在太大了，因此需要采用简化方法。可以将0～255分成四个区：0～63为第0区，64～127为第1区，128～191为第2区，192～255为第3区。这意味着红绿蓝分别有4个区，总共可以构成64种组合（4的3次方）。</li>
<li>任何一种颜色必然属于这64种组合中的一种，这样就可以统计每一种组合包含的像素数量。</li>
<li><img src="/images/oc_algorithm1.png"></li>
<li>上图是某张图片的颜色分布表，将表中最后一栏提取出来，组成一个64维向量(7414, 230, 0, 0, 8, &hellip;, 109, 0, 0, 3415, 53929)。这个向量就是这张图片的特征值或者叫"指纹"。</li>
<li>于是，寻找相似图片就变成了找出与其最相似的向量。这可以用皮尔逊相关系数或者余弦相似度算出。</li>
</ul>


<h4>内容特征法</h4>

<ul>
<li>除了颜色构成还可以从比较图片内容的相似性入手</li>
<li>首先

<ul>
<li>把图片装成一张比较小的灰度图片，假设为50*50像素。然后，确定一个阀值，把灰度图片转成黑白图片</li>
</ul>
</li>
<li>其次

<ul>
<li>如果两张图片很相似，那么他们的黑白轮廓应该是相近的。因此，问题就变成了如何去顶一个合理的阀值，正确的呈现图片中的轮廓</li>
</ul>
</li>
<li>因此

<ul>
<li><strong>前景色和背景色反差越大，轮廓就越明显</strong></li>
<li>这意味着，如果我们找到一个值，可以使得前景色和背景色格子的“类内差异最小”，或者“类间差异最大”，那么这个值就是理想的阀值</li>
</ul>
</li>
<li>后来因为有个如本的学者叫大津展之证明了两个是一样的，可以用他的“大津法”来求阀值

<ul>
<li>假定一张图片共有n个像素，其中灰度值小于阈值的像素为 n1 个，大于等于阈值的像素为 n2 个（ n1 + n2 = n ）。w1 和 w2 表示这两种像素各自的比重。

<ul>
<li>w1 = n1 / n</li>
<li>w2 = n2 / n</li>
</ul>
</li>
<li>再假定，所有灰度值小于阈值的像素的平均值和方差分别为 μ1 和 σ1，所有灰度值大于等于阈值的像素的平均值和方差分别为 μ2 和 σ2。于是，可以得到

<ul>
<li>类内差异 = w1(σ1的平方) + w2(σ2的平方)
　　      &ndash; 类间差异 = w1w2(μ1-μ2)^</li>
</ul>
</li>
<li>可以证明，这两个式子是等价的：得到"类内差异"的最小值，等同于得到"类间差异"的最大值。不过，从计算难度看，后者的计算要容易一些。</li>
<li>下一步用"穷举法"，将阈值从灰度的最低值到最高值，依次取一遍，分别代入上面的算式。使得"类内差异最小"或"类间差异最大"的那个值，就是最终的阈值.</li>
<li><p>有了50x50像素的黑白缩略图，就等于有了一个50x50的0-1矩阵。矩阵的每个值对应原图的一个像素，0表示黑色，1表示白色。这个矩阵就是一张图片的特征矩阵。</p></li>
<li><p>两个特征矩阵的不同之处越少，就代表两张图片越相似。这可以用"异或运算"实现（即两个值之中只有一个为1，则运算结果为1，否则运算结果为0）。对不同图片的特征矩阵进行"异或运算"，结果中的1越少，就是越相似的图片。</p></li>
</ul>
</li>
</ul>


<h3>objective c源码</h3>

<ul>
<li>tphash.h</li>
</ul>


<p>```</p>

<h1>import &lt;Foundation/Foundation.h></h1>

<p>@interface tphash : NSObject</p>

<ul>
<li>(uint64_t)ptHash:(UIImage*)image;</li>
<li>(int)hamdistance:(uint64_t)x with:(uint64_t) y;</li>
<li>(UIImage <em>)scaleImage:(UIImage </em>)image toSize(CGSize)newSize;</li>
<li>(uint64_t <em>) convertTogreyscale64Array: (UIImage </em>)i;</li>
</ul>


<p>@end
```</p>

<ul>
<li>tphash.m</li>
</ul>


<p>```</p>

<h1>import &ldquo;tphash.h&rdquo;</h1>

<p>@implementation tphash</p>

<ul>
<li><p>(uint64_t)ptHash:(UIImage <em>)image{
  image = [self scaleImage:image toSize:CGSizeMake(8,8)];
  uint64_t</em> imageArray = [self convertTogreyscale64Array:image];
  int sum = 0;
  for(int i = 0; i &lt; 64; i++){
      sum += imageArray[i];
  }
  uint8_t avg = sum/64;
  uint64_t ret = 0;
  for(int i = 0; i &lt; 64; i++){
      if(imageArray[i] >= avg){
          ret++;
      }
      ret &lt;&lt;= 1;
  }
  return ret;
}</p></li>
<li><p>(int)hamdistance:(uint64_t)x with:(uint64_t) y{
  unsigned dist = 0, val = x<sup>y</sup>;
  while (val) {
      ++dist;
      val &amp;= val &ndash; 1;
  }
}</p></li>
<li><p>(UIImage <em>)scaleImage:(UIImage </em>)image toSize(CGSize)newSize{
  UIGraphicsBeginIMageContextWithOptions(newSize, NO, 0.0);
  [image drawInRect:CGRectMake(0,0,newSize.width, newSize.height)];
  UIImage *newImage = UIGraphicsBeginImageFromCurrentImageContext();
  UIGraphicsEndImageContext();
  return newImage;
}</p></li>
<li><p>(uint64_t <em>) convertTogreyscale64Array: (UIImage </em>)i{
  int kRed = 1;
  int kGreen = 2;
  int kBlue = 4;</p>

<p>  int colors = kGreen;
  int m_width = i.size.width;
  int m_height = i.size.height;</p>

<p>  uint32_t <em>rgbImage = (uint32_t </em>) malloc(m_width * meight * sizeof(uint32_t));
  CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
  CGContextRef context = CGBitmapContextCreate(rgbImage, m_width, m_height, 8, m_width * 4, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaNoneSkipLast);
  CGContextSetInterpolationQuality(context, kCGInterpolationHigh);
  CGContextSetShouldAntialias(context, NO);
  CGContextDrawImage(context, CGRectMake(0, 0, m_width, m_height), [i CGImage]);
  CGContextRelease(context);
  CGColorSpaceRelease(colorSpace);</p>

<p>  uint8_t <em>m_imageData = (uint8_t </em>) malloc(m_width * m_height);
  for(int y = 0; y &lt; m_height; y++) {
      for(int x = 0; x &lt; m_width; x++) {
          uint32_t rgbPixel=rgbImage[y<em>m_width+x];
          uint32_t sum=0,count=0;
          if (colors &amp; kRed) {sum += (rgbPixel>>24)&255; count++;}
          if (colors &amp; kGreen) {sum += (rgbPixel>>16)&255; count++;}
          if (colors &amp; kBlue) {sum += (rgbPixel>>8)&255; count++;}
          m_imageData[y</em>m_width+x]=sum/count/4;
      }
  }
  free(rgbImage);
  return m_imageData;
}
@end</p></li>
</ul>


<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tree Based Ensemble Method Introduction]]></title>
    <link href="http://pbking1.github.com/blog/2014/05/08/tree-based-ensemble-method-introduction/"/>
    <updated>2014-05-08T18:30:07+08:00</updated>
    <id>http://pbking1.github.com/blog/2014/05/08/tree-based-ensemble-method-introduction</id>
    <content type="html"><![CDATA[<h3>Tree-based ensemble methods</h3>

<pre><code>random forest
gradient boosted decision trees
</code></pre>

<ul>
<li>main idea is greedy algorithm

<ul>
<li>通过构造一棵决策树分类器</li>
</ul>
</li>
<li>随机森林是通过构造10000课树</li>
</ul>


<!--more-->


<h4>决策树</h4>

<ul>
<li>其实就是二叉树</li>
<li>实际应用，一般为二叉树</li>
<li>每个非叶子节点都是一个分割

<ul>
<li>相当于一个分类条件</li>
</ul>
</li>
<li>每个叶子节点都是一类性质相同的样本</li>
<li><p>用同一种数据存在多种构造决策树的情况</p></li>
<li><p>决策树使用来分类的模型</p>

<ul>
<li>相当于svn和LR</li>
</ul>
</li>
<li>如何建树

<ul>
<li>是一种回归分类算法

<ul>
<li>“切分”和“解决”</li>
</ul>
</li>
<li>一开始的时候，所有的训练样本都在根部</li>
<li>然后分类的样本将基于选择的分类属性进行递归。</li>
</ul>
</li>
<li>理论上特征是可以重复选的</li>
<li>怎么找到比较好的树？

<ul>
<li>模型准确率高</li>
<li>找到尽可能最小的数来满足数据

<ul>
<li>分枝少</li>
<li>节点少</li>
</ul>
</li>
<li>occam&rsquo;s Racor：在效果超不多的时候，选比较简单的模型</li>
</ul>
</li>
<li>基本策略

<ul>
<li>贪心

<ul>
<li>当前把每个节点中的最优的特征作为分类标准</li>
<li>这样就不用穷举</li>
<li>评估

<ul>
<li>基尼系数（Gini index）</li>
<li>信息增益

<ul>
<li>用熵来衡量</li>
<li>混乱程度

<ul>
<li>如果容易分别出那个分类多，则混乱程度小</li>
<li>反之同理</li>
</ul>
</li>
<li>e.g 99/1（小） 50/50（大）</li>
</ul>
</li>
<li>则把每个叶子节点的熵都算出来

<ul>
<li>然后整棵树的熵则是用所有叶子节点的熵加权</li>
</ul>
</li>
<li>把分割前的熵减掉分割之后的，就是信息增益

<ul>
<li>如果比较大，那么就比较好</li>
</ul>
</li>
</ul>
</li>
<li> Gini index

<ul>
<li> 把叶子节点的熵换掉</li>
<li> 换成基尼系数</li>
<li> 基本上也是混乱度</li>
<li> 只是公式不一样了</li>
</ul>
</li>
<li> 整棵树的Gini系数是加权的分支的基尼</li>
<li> 如何防止overfitting？

<ul>
<li> 早一点停止树的增长</li>
<li> 先把所有节点来构造树，然后用的是90%的样本

<ul>
<li> 然后用剩下的样本来检验效果</li>
<li> 但是太慢了</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Bagging

<ul>
<li>构造k棵树</li>
<li>每棵树在1000各样本中随机选900个,构造决策树（只筛选样本）

<ul>
<li>然后把所有树的据结果统计，如果是分类问题，就少数服从多数。</li>
<li>随机选出的数据室可以重复的。</li>
</ul>
</li>
<li>如果是回归问题，则最终直接相加</li>
</ul>
</li>
<li><p>random forest</p>

<ul>
<li>不使用全部特征</li>
<li>不单只筛选样本，也筛选特征。</li>
<li>e.g 每次只用随机抽取的70%的样本，只用50%随机抽取的特征，来建立决策树</li>
<li>是目前分类回归中最好的off-the-shelf的算法

<ul>
<li>即拿即用</li>
</ul>
</li>
</ul>
</li>
<li><p>这两个算法加上boosting的不同在于训练集的构造的不同。</p></li>
<li>Boosting

<ul>
<li>结果是把每棵决策树的结果加权加起来</li>
<li>所有样本的权值加起来为1</li>
<li>对那些错的样本，权值是比较大的</li>
<li>缺点是在高噪声的环境下效果很不好

<ul>
<li>优点是在低噪声环境下效果很好</li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CPSO-Sk 的实现(1)]]></title>
    <link href="http://pbking1.github.com/blog/2014/04/09/cpso-sk-de-shi-xian-1/"/>
    <updated>2014-04-09T00:36:53+08:00</updated>
    <id>http://pbking1.github.com/blog/2014/04/09/cpso-sk-de-shi-xian-1</id>
    <content type="html"><![CDATA[<ul>
<li>其实和标准的PSO是一样的</li>
<li><p>只是初始种群是不一样的</p>

<ul>
<li>假设标准版的种群大小是100的话，那么</li>
<li>这个版本是把100分成10份，然后再对每一份使用标准版的算法</li>
</ul>
</li>
<li><p>因此这两个算法本质上没有区别，只是初始种群大小不一样而已</p></li>
</ul>


<!--more-->


<ul>
<li>以下是伪代码</li>
</ul>


<h3>伪代码</h3>

<ul>
<li>假设我们的算法初始种群分成10份</li>
</ul>


<p>```
如何初始化：
for i=0:种群大小</p>

<pre><code>for j=0:维度{
    对每个个体的位置进行随机化
    对每个个体的速度进行随机化
    对每个个体的最佳位置为粒子的位置
}
</code></pre>

<p>for i=0:种群大小{</p>

<pre><code>计算适应度
把每个粒子的最佳适应度初始化为初始值
</code></pre>

<p>}
把全局最优初始化为0   <br/>
```</p>

<p>```
更新局部最优值
if(如果粒子的最佳适应度比现在的适应度 大)</p>

<pre><code>for i=0:维度
    把粒子的历史最佳更新为粒子的位置
把粒子的最佳适应度更新为粒子现在的适应度
</code></pre>

<p>```</p>

<p>```
全局最优：
if(索引为0)</p>

<pre><code>for i=1:种群大小
    if(适应度小于索引第一个粒子的适应度){
        把s=第i个粒子的适应度
        flag=i
    }
for i=0:维度
    把全局最优位置更新为第flag个的位置
把全局最适应的值更新为第flag个的适应值
</code></pre>

<p>else{</p>

<pre><code>for i=0:种群大小
    if（如果最佳适应值小于全局最优）{
        for i=0:维度
            把最佳适应度更新成现在这个粒子的最佳适应度
        把全局最佳适应度更新为现在粒子的最佳适应度
    }
</code></pre>

<p>}
```</p>

<p><code>
计算适应值函数
</code></p>

<p>```
首先把种群分成10份，为了方便起见，相当于每相隔10个就停止然后对这10个粒子用PSO
然后就开始对包含10个粒子的子种群</p>

<pre><code>定义最大循环次数，建立一个循环
    if（达到最大循环次数或者满足停止条件）
        输出最佳适应值和取得这个值所需要的迭代次数
    else{
        for i=1:种群大小{
            for i=1:维度{
                更新个体速度：使用公式一
                判断速度是否超过最大速度
                    如果超过了就把速度更新给最大速度
                判断位置是否越界（小于最小值或者大于最大值）
                    乘上对应边界的两倍再减掉现在的位置
            }
            计算适应值
            计算局部最优解
        }
        计算全局最优
    }
</code></pre>

<p>```</p>

<h3>C++ source code</h3>

<p>```</p>

<h1>include<iostream></h1>

<h1>include<cmath></h1>

<h1>include<cstdlib></h1>

<h1>include<cstdio></h1>

<h1>include &ldquo;data.h&rdquo;</h1>

<p>using namespace std;</p>

<h1>define C1 2</h1>

<h1>define C2 2</h1>

<h1>define VMAX 5.0</h1>

<h1>define Iteration 10000</h1>

<h1>define rand1() (double)(rand() / (double)RAND_MAX)</h1>

<p>double global_best = 10000.0;
double v[100000] = {0};
const int X_const = 5;
double time_pso = 0.0;</p>

<p>struct particle{</p>

<pre><code>double current;
double personal_best;
</code></pre>

<p>};</p>

<p>struct particle p[100000];</p>

<p>double fitness(double x){</p>

<pre><code>return x * x - 20 * x + 100;
</code></pre>

<p>}</p>

<p>void init(){</p>

<pre><code>int i;                                                                                                                                     
for(i = 0; i &lt; 100000; i++){                                                                                                            
    p[i].current = -2 + i;                                                                                                                 
    p[i].personal_best = p[i].current;                                                                                                     
    v[i] = 0;                                                
}
</code></pre>

<p>}</p>

<p>void cpso_sk(){</p>

<pre><code>int iter = 1;
clock_t start, end;
start = clock();
int particle_num = 100000;
int split = 1000;
int count = particle_num / split;
for(int i = 0; i &lt; particle_num; i+=count){
    while(iter &lt; Iteration){
        for(int j = i; j &lt; count; j++)
            if(fitness(p[j].current) &lt; fitness(p[j].personal_best))
                p[j].personal_best = p[j].current;
        for(int k = i; k &lt; count; k++)
            if(fitness(p[k].current) &lt; fitness(global_best))
                global_best = p[k].current;
        for(int u = i; u &lt; count; u++){
            v[u] =X_const * (v[u] + C1 * rand1() * (p[u].personal_best - p[u].current) + C2 * rand1() * (global_best - p[u].current));
            if(v[u] &gt; VMAX)
                v[u] = VMAX;
        }
        for(int j = i; j &lt; count; j++)
            p[j].current += v[j];
        iter++;
    }
    end = clock();
    time_pso = end - start;
}
</code></pre>

<p>}</p>

<p>int main(){</p>

<pre><code>init();
cpso_sk();
cout&lt;&lt;"The cpso algorithm use "&lt;&lt;time_pso&lt;&lt;" in the funtion 1 and the global best is "&lt;&lt;global_best;
return 0;
</code></pre>

<p>}</p>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to Genentic Algorithm]]></title>
    <link href="http://pbking1.github.com/blog/2014/04/09/intro-to-genentic-algorithm/"/>
    <updated>2014-04-09T00:33:05+08:00</updated>
    <id>http://pbking1.github.com/blog/2014/04/09/intro-to-genentic-algorithm</id>
    <content type="html"><![CDATA[<ul>
<li>genentic algorithm</li>
<li>是一种由进化的灵感的来的算法，基于生物进化的机制</li>
<li>可用于解决类似于单染色体类型的数据结构</li>
<li>也可以被视为函数优化器</li>
<li>适合于使用大型潜在的搜索空间并且引导他们。并且找到最优的组合。</li>
<li>由john Holland提出的</li>
<li>可以为优化和机器学习提供便捷有效的方法</li>
</ul>


<!--more-->


<h4>思想</h4>

<ul>
<li>一定数量的种群的解根据时间进化，并且在每一代进化之后都变得更加健壮</li>
<li>并且每一个子代都是有父代交叉并且随机变化，还有其他的基因操作</li>
</ul>


<h4>组成</h4>

<ul>
<li>基本的基因数量（基因，染色体）

<ul>
<li>二进制字符串</li>
<li>实数</li>
<li>有规则</li>
</ul>
</li>
<li>初始化(创造)</li>
<li>父母选择（产生后代）

<ul>
<li>随机选择父母（通过贝叶斯概率分布）</li>
<li>染色体的改动

<ul>
<li><strong>交叉</strong>和<strong>重组</strong>

<ul>
<li>交叉

<ul>
<li>导致搜索空间中的移动</li>
<li>在种群中存储丢失的信息</li>
</ul>
</li>
<li>重组

<ul>
<li>这个可以在种群进化的初期加快搜索速度</li>
<li>它会导致一个有效的基因模板组合</li>
</ul>
</li>
</ul>
</li>
<li>一个Evaluator是连接传统遗传算法和他解决的问题的唯一连接

<ul>
<li>他会解码染色体并且分配给他一个健壮的方案</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>进化函数（环境）</li>
<li>基因操作（随机重组）</li>
<li>参数设置（训练）</li>
</ul>


<h4>好处</h4>

<ul>
<li>概念容易理解</li>
<li>模式和应用分离开来</li>
<li>支持多对象优化</li>
<li>适合噪音比较多的环境</li>
<li>总能找到答案，并且答案随着时间的变化而变好</li>
<li>总是并行的，容易分布</li>
<li>如果已经获得了那个遗传算法应用的知识，那么有很多种方法来加速和改进遗传算法</li>
<li>容易去使用或者利用以前的或者自动的求解结果</li>
</ul>


<h4>什么时候要用</h4>

<ul>
<li>交替的结果太慢或者太复杂</li>
<li>需要一个实验性的工具来检测新的逼近</li>
<li>一个和曾经被解决的问题很相似的问题</li>
<li>相混合一个已经存在的解法</li>
</ul>


<h4>算法流程</h4>

<ul>
<li>伪代码</li>
</ul>


<p>```
initialize node poupulation;
evaluate node population;
while(Termination){</p>

<pre><code>select parent nodes for reproduction;
perform recombination and mutation;
evaluate population;
</code></pre>

<p>}
```</p>

<h4>我的看法</h4>

<ul>
<li>就是不停地优化后代</li>
</ul>

]]></content>
  </entry>
  
</feed>
