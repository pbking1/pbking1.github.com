<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cplusplus | KING]]></title>
  <link href="http://pbking1.github.com/blog/categories/cplusplus/atom.xml" rel="self"/>
  <link href="http://pbking1.github.com/"/>
  <updated>2015-03-12T13:19:22-04:00</updated>
  <id>http://pbking1.github.com/</id>
  <author>
    <name><![CDATA[pb]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[difference between malloc and new in C++]]></title>
    <link href="http://pbking1.github.com/blog/2015/01/27/difference-between-malloc-and-new-in-c-plus-plus/"/>
    <updated>2015-01-27T15:30:52-05:00</updated>
    <id>http://pbking1.github.com/blog/2015/01/27/difference-between-malloc-and-new-in-c-plus-plus</id>
    <content type="html"><![CDATA[<h3>new and delete</h3>

<ul>
<li>the way it allocate and release memory

<ul>
<li>the memory is allocate from <code>Free Store</code></li>
<li>will return a fully typed pointer

<ul>
<li>if failed will not return NULL</li>
</ul>
</li>
<li>the compiler will calculate the size</li>
<li>reallocate is not handled intuitively, using copy constructor</li>
<li>whether called malloc and delete can be user defined</li>
<li>can add a new memory allocator to deal with low memory</li>
<li>new and delete can be overwrite legally</li>
<li>use constructor/destructor to initial/destory object</li>
</ul>
</li>
</ul>


<!--more-->


<ul>
<li><p>new 动态创建和释放数组或者单个对象</p>

<ul>
<li>动态创建对象的时候，只需要指定其数据类型，不必为该对象命名</li>
<li>如果分配失败了，会抛出异常。</li>
<li>new 表达式返回指向该新建对象的指针</li>
<li>我们可以通过这个指针来访问新建的对象</li>
<li>int *p = new int

<ul>
<li>返回类型为int*类型， 分配大小为sizeof(int)</li>
</ul>
</li>
<li>int *p = new int[100]

<ul>
<li>返回类型为int*类型, 分配大小为sizeof(int) * 100</li>
</ul>
</li>
</ul>
</li>
<li><p>三种特殊指针</p>

<ul>
<li>void* 表示未确定类型的指针，更明确的说是指申请内存空间时还不知道user是用来储存什么类型的数据的。</li>
<li>零值指针：值为0的指针。可以是任何一种指针类型。</li>
<li>NULL指针：不提供任何地址信息的指针</li>
</ul>
</li>
<li><p>new 动态创建的对象是可以初始化的。</p>

<ul>
<li>e.g int *p = new int(1000)</li>
<li>如果不初始化，就会使用这个类的默认构造函数来初始化。

<ul>
<li>e.g int *p = new int()  //初始化为0</li>
</ul>
</li>
<li>但是如果对象是内置的，就没有初始化

<ul>
<li>e.g int *p = new int //指向一个没有初始化的int

<ul>
<li>string *str = new string()  //初始化为空串，因为string自带的默认构造函数会初始化为空串</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>delete</p>

<ul>
<li>delete p;

<ul>
<li>但是释放完p的内存之后，p会变成不确定的指针</li>
<li>因此要把p赋值为0

<ul>
<li>明确指针不再指向任何对象</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>malloc and free</h3>

<ul>
<li><p>the way it allocate and release memory</p>

<ul>
<li>the memory is allocate from <code>Heap</code></li>
<li>will return a void pointer

<ul>
<li>will return NULL if failed</li>
</ul>
</li>
<li>the space and size need to be specified(固定)</li>
<li>will not called new/delete</li>
<li>it is simple to reallocate large memory</li>
<li>user can not write code into allocation sequence to help with low memory</li>
<li>malloc/free can not be overriden legally</li>
</ul>
</li>
<li><p>malloc 动态内存分配</p>

<ul>
<li>void *malloc(int size)</li>
<li>向系统申请分配指定size个字节的内存空间</li>
<li>申请之后要检查是否分配成功</li>
<li>不用之后要释放：把纸箱这块内存的指针指向NULL, 防止程序不小心使用了它

<ul>
<li>如果忘了释放就是内存泄露</li>
</ul>
</li>
<li>操作系统中有一个记录空闲内存位置的链表，每次收到程序申请的时候，就会遍历这个链表，找到第一个空间大于申请的空间的堆节点，然后把该节点从链表中删除，把这个节点的空间分配给程序。</li>
<li> int p;

<ul>
<li>p = (int*)malloc(sizeof(int) * 128)</li>
<li>p指针会存储存储单元的首地址</li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mpi_parallel_programming_2]]></title>
    <link href="http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-2/"/>
    <updated>2014-09-15T15:28:34-04:00</updated>
    <id>http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-2</id>
    <content type="html"><![CDATA[<h3>data type</h3>

<ul>
<li><p>there are only these data type in the MPI</p>

<ul>
<li>if you want to use struct or multi array, you need to do something else</li>
</ul>
</li>
<li><table>
<thead>
<tr>
<th></th>
<th>MPI data type</th>
<th> c data type</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>MPI_CHAR</td>
<td>signed char|</td>
</tr>
<tr>
<td></td>
<td>MPI_SHORT</td>
<td>signed short int|</td>
</tr>
<tr>
<td></td>
<td>MPI_INT</td>
<td>signed int|</td>
</tr>
<tr>
<td></td>
<td>MPI_LONG</td>
<td>signed long int|</td>
</tr>
<tr>
<td></td>
<td>MPI_UNSIGNED_CHAR</td>
<td>unsigned long int|</td>
</tr>
<tr>
<td></td>
<td>MPI_UNSIGNED_SHORT</td>
<td>unsigned short int|</td>
</tr>
<tr>
<td></td>
<td>MPI_UNSIGNED</td>
<td>unsigned int|</td>
</tr>
<tr>
<td></td>
<td>MPI_FLOAT</td>
<td>float|</td>
</tr>
<tr>
<td></td>
<td>MPI_DOUBLE</td>
<td>double|</td>
</tr>
<tr>
<td></td>
<td>MPI_LONG_DOUBLE</td>
<td>long double|</td>
</tr>
<tr>
<td></td>
<td>MPI_BYTE</td>
<td>|</td>
</tr>
<tr>
<td></td>
<td>MPI_MPI_PACKED</td>
<td>|</td>
</tr>
</tbody>
</table>
</li>
</ul>


<!--more-->


<h3>about the status</h3>

<ul>
<li>the MPI_status combine a lots of information

<ul>
<li>there are at least three member in the status

<ul>
<li>MPI_SOURCE, MPI_TAG, MPI_ERROR</li>
</ul>
</li>
</ul>
</li>
<li>and we can get the size of the message using

<ul>
<li>MPI_Get_Count(MPI_Status <em>status, MPI_Datatype datatype, int</em> count_ptr);</li>
</ul>
</li>
</ul>


<h3>The broadcast idea</h3>

<ul>
<li>you can use the MPI_Bcast idea to send the message to all the other process;

<ul>
<li>MPI_Bcast(void *message, int count, MPI_Datatype datatype, int root, MPI_Comm comm)</li>
</ul>
</li>
</ul>


<h3>gather the data and scatter the data</h3>

<ul>
<li>use MPI_Gather

<ul>
<li>MPI_Gather(void <em>send_data, int send_count, MPI_Datatype send_type, void</em> recv_data, int recv_count, MPI_Datatype recv_type, int root, MPI_Comm comm)</li>
</ul>
</li>
<li>use MPI_Scatter to scatter the data

<ul>
<li>MPI_Scatter(void <em>send_data, int send_count, MPI_Datatype send_type, void </em>recv_data, int recv_count, MPI_Datatype recv_type, int root, MPI_Comm comm);</li>
<li>MPI_Scatter split the data referenced by send_data on the process with rank root into k segment.each of which consists of send_count elements of type send_type.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mpi_parallel_programming_1]]></title>
    <link href="http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-1/"/>
    <updated>2014-09-15T14:19:13-04:00</updated>
    <id>http://pbking1.github.com/blog/2014/09/15/mpi-parallel-programming-1</id>
    <content type="html"><![CDATA[<h3>difference between SIMD and MIMD</h3>

<ul>
<li>difference kinds of computer architecture is using the Flynn to classify

<ul>
<li>SISD</li>
<li>SIMD</li>
<li>MISD</li>
<li>MIMD</li>
</ul>
</li>
<li>we only talk about the SIMD and MIMD here

<ul>
<li>SIMD means that one command deal with many data streams

<ul>
<li>most of the single core machine is SIMD machine</li>
<li>and these kinds of machine is most used in the image processing and multimedia processing.</li>
</ul>
</li>
</ul>
</li>
</ul>


<!--more-->


<pre><code>- MIMD means that many commands deal with many data streams
    - the lastest multicore platform is a MIMD machine
    - the MIMD are asynchronous
    - 
</code></pre>

<h4>the multi core hardware architecture</h4>

<ul>
<li>the multicore CPU is combine many CPU into one chip. and each CPU core has a single processor.

<ul>
<li>each core has it&rsquo;s own cache. (some other may share one cache between multi CPU)</li>
</ul>
</li>
</ul>


<h3>message passing</h3>

<ul>
<li>There are two methods in the message passing

<ul>
<li>MPI_Send

<ul>
<li>void * buffer, int count, MPI_Datatype datatype, int destination, int tag, MPI_Comm communicator</li>
<li>e.g

<ul>
<li>MPI_Send(&amp;x, 1, MPI_FLOAT, 1, 0, MPI_COMM_WORLD);</li>
</ul>
</li>
</ul>
</li>
<li>MPI_Recv

<ul>
<li>void * buffer, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm communicator, MPI_Status status</li>
<li>MPI_Recv(&amp;x, 1, MPI_FLOAT, 0, 0, MPI_COMM_WORLD, &amp;status);</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>sample program</h3>

<p>```</p>

<h1>include &ldquo;mpi.h&rdquo;</h1>

<p>int main(int argc, char *argv[]){</p>

<pre><code>int rank; //rank of the process
int source; //rank of the sender
int dest;   //rank of the receiver
int num;    //number of the processers
int tags;
char messages[1000];
MPI_Status status;

//setting up the MPI
MPI_init(&amp;argc, &amp;argv);

//find out the rank of the curret program
MPI_Comm_rank(MPI_COMM_WORLD, rank);

//find out the number of the processers
MPI_Common_Size(MPI_COMM_WORLD, &amp;p);

if(rank != 0){ //if the current program is not the root program
    sprintf(message, "hello from %d", rank);
    dest = 0;
    MPI_Send(message, strlen(message) + 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);
}else{
    sprintf(message, "hello from ");
    MPI_Recv(message, 100, MPI_CHAR, source, tag, MPI_COMM_WORLD, &amp;status);
    printf("%s\n", message);
}
MPI_Finalize();
</code></pre>

<p>}</p>

<p>```</p>

<h3>how to run the program</h3>

<ul>
<li>for c++

<ul>
<li><code>mpic++ -o test test.cpp</code></li>
</ul>
</li>
<li>for c

<ul>
<li><code>mpicc -o test test.c</code></li>
</ul>
</li>
<li>run

<ul>
<li>for m core computer

<ul>
<li><code>mpirun -np m test</code></li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
